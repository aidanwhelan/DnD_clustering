{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A Dungeon Master's Guide to Clustering**\n",
    "This hands-on workshop sits at the intersection of classic machine learning techniques and Dungeons & Dragons, the classic tabletop roleplaying game that's celebrated by generations.  \n",
    "\n",
    "You will be guided through the elegant and powerful **K-means clustering algorithm** as you cluster fantasy monsters by their in-game attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "These libraries will have been installed on your local machine with the requirements.txt file provided in the workshop directory. If you have not yet done so, please run the following command from the workshop directory: `pip3 install -r requirements.txt`  \n",
    "\n",
    "With these tools, you will be able to perform valuable matrix operations, read in comma-delimited data files (.CSVs), and create interactive, 3D visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "\n",
    "import numpy as np              #for arrays and matrices\n",
    "import matplotlib.pyplot as plt #for plots and graphs (here, backend for Seaborn)\n",
    "import pandas as pd             #for reading .CSV files and creating data tables (dataframes)\n",
    "import seaborn as sns           #for elegant plotting utilities\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D #for interactive, 3D graphs\n",
    "\n",
    "sns.set(style = \"darkgrid\")     #cosmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset\n",
    "Here, you will import the data file **monsters.csv** which contains information about many of the monsters that might appear in Dungeons & Dragons. Although this file includes everything from the monsters' names to their native environments, we will only use some of the information in our analysis.  \n",
    "\n",
    "In this step, we will read in the information from the CSV file and put it in a Pandas dataframe. A dataframe is a useful utility for storing information in easily-accessible tables. After creating the dataframe, take a look at what you've built!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_monsters =   #read in CSV file to Pandas dataframe\n",
    "\n",
    "  #preview your new Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Visualization  \n",
    "Now that the monsters have been loaded into a clean Pandas dataframe, let's visualize some of the relationships between some of the most relevant pieces of monster information. To do this, we'll call on Matplotlib for plotting utilities.  \n",
    "\n",
    "Let's create a 3D plot with which we can interact. Because Pandas dataframes are designed for accessibility, we can dial up information on any monster attribute by column name! To set the values for each axis in our plot, we can choose some numerical parameters that describe monsters.  \n",
    "\n",
    "You can try visualizing loads of different combinations, but for now, let's take a look at **Hit Points**, **Armor Class**, and **Strength**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Using K-means  \n",
    "Now that our data is loaded in and we can see it plotted in 3D space, it would be great to get some extra intuition about how these monsters relate to one another! Maybe my character knows that they're particularly effective against a certain monster and wants to know which monsters are most similar for greatest effect!  \n",
    "\n",
    "**Enter: the clustering algorithms**  \n",
    "\n",
    "With clustering algorithms, we can learn a bit about how subjects relate or can most aptly be grouped based solely on the information we have on-hand.  \n",
    "\n",
    "One such algorithm which is both powerful and intuitive is the **K-means clustering algorithm**. The core concept behind K-means is the movement of cluster centers, or \"centroids\", to best describe the set of points in n-dimensional space that are closest to them. Ideally, after a series of updates and corrections, these centroids will land in space at places that best describe \"clusters\", or groups of data points that have the most in common.  \n",
    "\n",
    "### Set Parameters and Initialize Centroids   \n",
    "To begin, we first need to determine the number of \"centroids\" that we want to use in our clustering. Because clusters are centered around these centroids, this will also end up being the number of clusters you create.  \n",
    "\n",
    "The number of centroids you set is typically referred to as \"K\", the term that gives the first half of the name \"K-means\".  \n",
    "\n",
    "Although these centroids are not themselves monster data points, we need to be able to describe them in multidimensional space, so we give them coordinates. Fortunately for us, the K-means algorithm will move the centroids itself when it begins, so we can initialize the centroids with random coordinates and toss them out into space.  \n",
    "\n",
    "The final parameter we'll need to set is the number of iterations we'd like the algorithm to run. Each iteration is an adjustment of the centroids' locations, and ideally the centroids will get closer to their final positions with each update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the number of clusters we expect to see\n",
    "k = \n",
    "\n",
    "#Choose the number of dimensions\n",
    "num_dimensions = \n",
    "\n",
    "#Choose number of iterations\n",
    "max_iterations = \n",
    "\n",
    "#Randomly initialize the coordinates of our K centroids\n",
    "centroids = []\n",
    "for i in range(k):\n",
    "    centroids.append(np.random.randint(20, size=(num_dimensions)))\n",
    "\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Calculating Distance  \n",
    "In order to determine the new coordinates of centroids with the \"means\" part of K-means, we need to know which groups of data points should be averaged for each centroid.  \n",
    "\n",
    "In K-means, we can use distance calculations to find the corresponding cluster for each data point. There are plenty of options for performing this distance calculation, but for this workshop, we'll use the tried-and-true Euclidean distance formula. The catch here is that we need to find the distance in multi-dimensional space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_dist_8D(point1, point2):\n",
    "    \n",
    "    return(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run K-means  \n",
    "So, we've sent our centroids out into space, but we need to know how to update their locations at each iteration. We've already addressed the \"K\" part of K-means, so this is where the \"means\" part kicks in.  \n",
    "\n",
    "At each update step, the new location of a centroid is the \"mean\" (or average) coordinate of all of the points in the centroid's current cluster. Simple enough!  \n",
    "\n",
    "Here, we run the algorithm over the chosen number of iterations. At each iteration, we go through every data point and assign it to the cluster of its closest centroid. When all data points have been assigned to clusters, we are free to recalculate the coordinates of the centroids by averaging all of the coordinates in their clusters.  \n",
    "\n",
    "Repeat this process, and at the end, the clusters will be finely-tuned and representative of similarities in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the algorithm for the chosen number of iterations\n",
    "for i in range(max_iterations):\n",
    "    \n",
    "    #Create bins for clusters\n",
    "    clusters = [[] for j in range(k)]\n",
    "    \n",
    "    #Assign each data point to a centroid (cluster)\n",
    "    for row in range(len(DF_monsters)):\n",
    "        point = []\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        point.append(DF_monsters.get('')[row])\n",
    "        \n",
    "        distances = []\n",
    "        \n",
    "        #Measure distances from the point to each centroid\n",
    "        for c in range(len(centroids)):\n",
    "            distances.append(euclidian_dist_8D(point,centroids[c]))\n",
    "        \n",
    "        #Find which centroid has the closest distance and bin the point\n",
    "        cluster_ID = np.argmin(distances)\n",
    "        clusters[cluster_ID].append((point,row))\n",
    "    \n",
    "    #Recalculate the centroids' coordinates\n",
    "    new_centroids = [[0 for m in range(num_dimensions)] for j in range(k)]\n",
    "    for c_ID in range(len(clusters)):\n",
    "        for j in range(len(clusters[c_ID])):\n",
    "            #Sum the coordinates of all data points in each centroid's cluster\n",
    "            new_centroids[c_ID] = np.add(new_centroids[c_ID],clusters[c_ID][j][0])\n",
    "    \n",
    "    for c_ID in range(len(clusters)):\n",
    "        if(len(clusters[c_ID])>0):\n",
    "            #Divide the summed coordinates by the number of coordinates that were summed to get the mean\n",
    "            new_centroids[c_ID] = new_centroids[c_ID] / len(clusters[c_ID])\n",
    "    \n",
    "    centroids = new_centroids    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results  \n",
    "And that's it! You've just clustered the monsters of Dungeons & Dragons! Now we can take a look at the clusters and see what intuition we can pull from our algorithm output.  \n",
    "\n",
    "In Dungeons & Dragons, one of the metrics used to measure monsters is Challenge Rating. One such way to explore our new clusters is to explore the Challenge Ratings of the monsters within the clusters. By measuring the average Challenge Rating and variance of the clusters, we can see if the data we've used implicitly groups monsters in a similar way to the Challenge Rating system.  \n",
    "\n",
    "With an Average Challenge Rating vs. Variance plot, we can visualize this relationship for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = []\n",
    "variances = []\n",
    "for i in range(len(clusters)):\n",
    "    print(\"There are {} monsters in class {}\".format(len(clusters[i]), i))\n",
    "    temp_challenge_ratings = [0]\n",
    "    for j in range(len(clusters[i])):\n",
    "        temp_challenge_ratings.append(DF_monsters.get('challenge_rating')[clusters[i][j][1]])\n",
    "    print(\"The average challenge rating is {}\".format(np.average(temp_challenge_ratings)))\n",
    "    print(\"The variance is {}\\n\".format(np.var(temp_challenge_ratings)))\n",
    "    \n",
    "    #Check for empty clusters\n",
    "    if(np.average(temp_challenge_ratings)!=0.0): averages.append(np.average(temp_challenge_ratings))\n",
    "    if(np.var(temp_challenge_ratings)!=0.0): variances.append(np.var(temp_challenge_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Visualization  \n",
    "All the hard work is done now, so it's time to sit back and enjoy our clusters in 3D space!  \n",
    "\n",
    "With a different color for each of our clusters, plot each point in each cluster. Even in the context of only three of our eight dimensions, we see that the clusters are grouping our monsters as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-workspace",
   "language": "python",
   "name": "dl-workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
